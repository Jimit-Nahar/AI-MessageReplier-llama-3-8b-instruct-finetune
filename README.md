# ğŸ¤– AI Message Replier â€” Fine-tuned LLaMA 3 + OCR Integration

A fine-tuned **LLaMA 3 8B Instruct** model paired with OCR, designed to intelligently and contextually reply to messages. This project aims to assist usersâ€”especially via a planned **web extension**â€”by generating relevant, human-like responses based on extracted text from message images.

---

## ğŸ“Œ Overview

This project focuses on:
- **Contextual AI messaging**: Using LLaMA 3 to understand and respond like a human, especially in Gen-Z lingo.
- **OCR-based input**: Extracting text from message screenshots to feed into the AI model.
- **Web integration**: (In progress) Building a browser extension for real-world use.

---

## ğŸ§  Fine-tuning Highlights

We fine-tuned **Metaâ€™s LLaMA 3 8B Instruct** model with a custom dataset focused on:
- **Gen-Z slang and internet culture**
- **Conversational style fine-tuning**
- **Message reply optimization**

The model is better equipped to handle casual, real-life texting formats and reply accordingly.

---

## ğŸ–¼ï¸ OCR with Python

To extract message content:
- Used **PyTesseract** (Tesseract OCR via Python)
- Converts message screenshots into clean, structured text
- Filters noise and focuses on key user content for response generation

## ğŸš€ Future Scope & Contributions
ğŸ”— Currently, the OCR and LLaMA model are not yet integrated.

Iâ€™m actively looking for community support to:

Connect OCR output to the LLaMA input pipeline

Package the system into a working browser extension

Optimize performance and latency for real-time usage

## ğŸ™Œ Pull requests, discussions, and bug reports are welcome!
Feel free to contribute, suggest features, or help solve errors.

## ğŸ“¬ Contact
For questions, collaborations, or suggestions, feel free to:

Open an issue

Start a GitHub discussion

Reach out via email (jimit.nahar@gmail.com)

