# 🤖 AI Message Replier — Fine-tuned LLaMA 3 + OCR Integration

A fine-tuned **LLaMA 3 8B Instruct** model paired with OCR, designed to intelligently and contextually reply to messages. This project aims to assist users—especially via a planned **web extension**—by generating relevant, human-like responses based on extracted text from message images.

---

## 📌 Overview

This project focuses on:
- **Contextual AI messaging**: Using LLaMA 3 to understand and respond like a human, especially in Gen-Z lingo.
- **OCR-based input**: Extracting text from message screenshots to feed into the AI model.
- **Web integration**: (In progress) Building a browser extension for real-world use.

---

## 🧠 Fine-tuning Highlights

We fine-tuned **Meta’s LLaMA 3 8B Instruct** model with a custom dataset focused on:
- **Gen-Z slang and internet culture**
- **Conversational style fine-tuning**
- **Message reply optimization**

The model is better equipped to handle casual, real-life texting formats and reply accordingly.

---

## 🖼️ OCR with Python

To extract message content:
- Used **PyTesseract** (Tesseract OCR via Python)
- Converts message screenshots into clean, structured text
- Filters noise and focuses on key user content for response generation

## 🚀 Future Scope & Contributions
🔗 Currently, the OCR and LLaMA model are not yet integrated.

I’m actively looking for community support to:

Connect OCR output to the LLaMA input pipeline

Package the system into a working browser extension

Optimize performance and latency for real-time usage

## 🙌 Pull requests, discussions, and bug reports are welcome!
Feel free to contribute, suggest features, or help solve errors.

## 📬 Contact
For questions, collaborations, or suggestions, feel free to:

Open an issue

Start a GitHub discussion

Reach out via email (jimit.nahar@gmail.com)

